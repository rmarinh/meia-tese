"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"MAGISTER: LLM-Based Test Generation with Role-Specialized Agents","A. Ahammad; M. El Bajta; M. Radgui","SI2M Laboratory, National Institute of Statistics and Applied Economics, Rabat, Morocco; SI2M Laboratory, National Institute of Statistics and Applied Economics, Rabat, Morocco; SI2M Laboratory, National Institute of Statistics and Applied Economics, Rabat, Morocco",2025 International Conference on Intelligent Systems: Theories and Applications (SITA),"9 Dec 2025","2025","","","1","7","Automated test generation is one of the most critical topics in software testing, with numerous challenges due to the need for deep code understanding and the creation of meaningful assertions. Traditional approaches often generate low-quality and difficult-to-read tests that lack real code understanding and rely on statistical and dynamic analysis. With the recent advances in Large Language Models (LLMs), new opportunities emerge for generating unit tests that prioritize readability and context understanding. In this paper, we introduce MAGISTER, a multiagent framework for LLM-based unit test generation, where each agent (Analyzer Agent, Test Generation Agent, Executor Agent, and Refiner Agent) specializes in a specific role within the framework workflow, which involves analyzing the codebase to identify testable units and generating test code with feedbackdriven refinement. We evaluated MAGISTER on five open-source Python projects, demonstrating a significant improvement in code coverage for modular codebases compared to the original userwritten tests. However, it still has limitations when handling large and complex projects requiring domain-specific knowledge. Our results demonstrate the promising potential of LLM-driven and agent-based architectures in advancing test automation while highlighting directions for future improvement.","","979-8-3315-5989-2","10.1109/SITA67914.2025.11273637","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11273637","Automated Test Generation;Large Language Models;Multi-Agent Systems;Unit Testing;LLM-based Testing","Software testing;Codes;Automation;Large language models;Manuals;Software reliability;Test pattern generators;Logic;Python;Multi-agent systems","","","","39","IEEE","9 Dec 2025","20-21 Oct. 2025","20-21 Oct. 2025","IEEE","IEEE Conferences"
"A Vision for Debiasing Confirmation Bias in Software Testing via LLM","I. Salman; M. Waseem; V. Mandić; R. D. De Alwis","School of Engineering Science, Lappeenranta-Lahti University of Technology LUT, Lahti, Finland; Faculty of Information Technology and Communications, Tampere University, Tampere, Finland; Faculty of Technical Sciences, University of Novi Sad, Novi Sad, Serbia; School of Engineering Science, Lappeenranta-Lahti University of Technology LUT, Lahti, Finland",2025 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM),"12 Jan 2026","2025","","","344","350","Background: Large language models (LLM) suffer from various forms of biases due to the biased datasets used to train the models. At the same time, human cognitive biases have an equal propensity to express themselves when using LLMs for software engineering tasks. Software testing is a critical phase of the software development life cycle. Confirmation bias is reported to have deteriorated software testing by designing more specification-consistent test cases compared to specificationinconsistent test cases. However, there is a lack of debiasing (mitigation) strategies in this regard. Aims: In this paper, first, we investigate whether the LLM model suffers from confirmation bias while performing software testing tasks. Second, we propose a vision of debasing confirmation bias in software testing via LLM. Method: We conducted an empirical study to detect confirmation bias by an LLM (ChatGPT4.0) in the design of functional test cases. Based on empirical findings, we used the analytical paradigm to design a multi-agent system. Results: We present a vision for debiasing confirmation bias in functional software testing by leveraging LLMs via a multi-agent approach. Conclusions: The proposed vision may improve the performance of LLMs in terms of reduced confirmation bias and serve as a debiasing technique for functional software testing.","","979-8-3315-9147-2","10.1109/ESEM64174.2025.00050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11323346","large language model;confirmation bias;functional software testing;debiasing;multi-agent","Software testing;Large language models;Prevention and mitigation;Software measurement;Software engineering;Software development management","","","","36","IEEE","12 Jan 2026","2-3 Oct. 2025","2-3 Oct. 2025","IEEE","IEEE Conferences"
"Evaluation of the Choice of LLM in a Multi-Agent Solution for GUI-Test Generation","S. Tomic; E. Alégroth; M. Isaac","Blekinge Institute of Technology, Karlskrona, Sweden; Blekinge Institute of Technology, Karlskrona, Sweden; Synteda, Gothenburg, Sweden","2025 IEEE Conference on Software Testing, Verification and Validation (ICST)","20 May 2025","2025","","","487","497","Automated testing, particularly for GUI-based systems, remains a costly and labor-intensive process and prone to errors. Despite advancements in automation, manual testing still dominates in industrial practice, resulting in delays, higher costs, and increased error rates. Large Language Models (LLMs) have shown great potential to automate tasks traditionally requiring human intervention, leveraging their cognitive-like abilities for test generation and evaluation. In this study, we present PathFinder, a Multi-Agent LLM (MALLM) framework that incorporates four agents responsible for (a) perception and summarization, (b) decision-making, (c) input handling and extraction, and (d) validation, which work collaboratively to automate exploratory web-based GUI testing. The goal of this study is to assess how different LLMs, applied to different agents, affect the efficacy of automated exploratory GUI testing. We evaluate PathFinder with three models, Mistral-Nemo, Gemma2, and Llama3.1, on four e-commerce websites. Thus, 27 permutations of the LLMs, across three agents (excluding the validation agent), to test the hypothesis that a solution with multiple agents, each using different LLMs, is more efficacious (efficient and effective) than a multi-agent solution where all agents use the same LLM. The results indicate that the choice of LLM constellation (combination of LLMs) significantly impacts efficacy, suggesting that a single LLM across agents may yield the best balance of efficacy (measured by F1-score). Hypothesis to explain this result include, but are not limited to: improved decision-making consistency and reduced task coordination discrepancies. The contributions of this study are an architecture for MALLM-based GUI testing, empirical results on its performance, and novel insights into how LLM selection impacts the efficacy of automated testing.","2159-4848","979-8-3315-0814-2","10.1109/ICST62969.2025.10989038","Vinnova(grant numbers:2024-00242); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10989038","Multi-Agent Systems;Large Language Models (LLMs);Automated Testing;MALLM;AI-Assisted Software Testing","Software testing;Adaptation models;Large language models;Decision making;Electronic commerce;Test pattern generators;Testing;Graphical user interfaces;Periodic structures;Multi-agent systems","","1","","33","IEEE","20 May 2025","31 March-4 April 2025","31 March-4 April 2025","IEEE","IEEE Conferences"
"MultiFuzz: A Dense Retrieval-based Multi-Agent System for Network Protocol Fuzzing","Y. Maklad; F. Wael; A. Hamdi; W. Elsersy; K. Shaban","Dept. of Computer Science, MSA University, Giza, Egypt; Dept. of Computer Science, MSA University, Giza, Egypt; Dept. of Computer Science, MSA University, Giza, Egypt; Dept. of Computer Science, MSA University, Giza, Egypt; Dept. of Computer Science, Qatar University, Doha, Qatar",2025 IEEE/ACS 22nd International Conference on Computer Systems and Applications (AICCSA),"5 Jan 2026","2025","","","1","8","Traditional protocol fuzzing techniques, such as those employed by AFL-based systems, often lack effectiveness due to a limited semantic understanding of complex protocol grammars and rigid seed mutation strategies. Recent works, such as ChatAFL, have integrated Large Language Models (LLMs) to guide protocol fuzzing and address these limitations, pushing protocol fuzzers to wider exploration of the protocol state space. But ChatAFL still faces issues like unreliable output, LLM hallucinations, and assumptions of LLM knowledge about protocol specifications. This paper introduces MultiFuzz, a novel dense retrieval-based multi-agent system designed to overcome these limitations by integrating semantic-aware context retrieval, specialized agents, and structured tool-assisted reasoning. MultiFuzz utilizes agentic chunks of protocol documentation (RFC Documents) to build embeddings in a vector database for a retrieval-augmented generation (RAG) pipeline, enabling agents to generate more reliable and structured outputs, enhancing the fuzzer in mutating protocol messages with enhanced state coverage and adherence to syntactic constraints. The framework decomposes the fuzzing process into modular groups of agents that collaborate through chain-of-thought reasoning to dynamically adapt fuzzing strategies based on the retrieved contextual knowledge. Experimental evaluations on the Real-Time Streaming Protocol (RTSP) demonstrate that MultiFuzz significantly improves branch coverage and explores deeper protocol states and transitions over state-of-the-art (SOTA) fuzzers such as NSFuzz, AFLNet, and ChatAFL. By combining dense retrieval, agentic coordination, and language model reasoning, MultiFuzz establishes a new paradigm in autonomous protocol fuzzing, offering a scalable and extensible foundation for future research in intelligent agentic-based fuzzing systems.","2161-5330","979-8-3315-5693-8","10.1109/AICCSA66935.2025.11315267","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11315267","Protocol Fuzzing;Network Security;Finite-State Machine;Reverse Engineering;Large Language Models;MultiAgent Systems;Dense Retrieval;Retrieval-Augmented Generation;Chain-of-Thoughts","Protocols;Large language models;Retrieval augmented generation;Semantics;Reverse engineering;Fuzzing;Syntactics;Cognition;Vectors;Multi-agent systems","","","","40","IEEE","5 Jan 2026","19-22 Oct. 2025","19-22 Oct. 2025","IEEE","IEEE Conferences"
"MCM: A Multi-Agent Collaborative Multimodal Framework For Traditional Chinese Medicine Diagnosis","C. Liang; Z. Ma; W. Wang; M. Ding; Z. Cao; M. Chen","Computer and Information Engineering College, Shanghai Polytechnic University; Mathematical and Science College, Shanghai Normal University; Shanghai Key Laboratory of Computer Software Testing and Evaluating; Shanghai Key Laboratory of Computer Software Testing and Evaluating; Computer and Information Engineering College, Shanghai Polytechnic University; Shanghai Key Laboratory of Computer Software Testing and Evaluating",2025 IEEE International Conference on Image Processing (ICIP),"18 Aug 2025","2025","","","1438","1443","The advancement of information technology and the rise of generative AI have paved the way for the development of Large Language Models (LLMs) tailored for TCM diagnostics. However, existing LLMs in the field of TCM face challenges in interpretability, limited modality in interaction, and robustness. To address these limitations, we propose MCM, a Multi-Agent Collaborative Multimodal Framework for TCM Diagnosis. This framework enables robust and interpretable multimodal diagnosis through multi-agent collaboration, offering novel methodologies for applying LLMs in the TCM domain. Experimental results demonstrate that the model within the MCM framework improved performance after fine-tuning, with additional capability gains under the MCM framework’s support, effectively addressing the challenges faced by LLMs in TCM, including interpretability, limited data modality, and lack of robustness. The code is open-sourced at: https://github.com/JerryMazeyu/MCM.","2381-8549","979-8-3315-2379-4","10.1109/ICIP55913.2025.11084334","Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11084334","Traditional Chinese Medicine;Large Language Model;Multi-Agent Collaboration;Multi-modality;Intelligent Diagnosis;Interpretability","Analytical models;Image analysis;Tongue;Large language models;Collaboration;Knowledge graphs;Medical services;Robustness;Vectors;Medical diagnostic imaging","","","","26","IEEE","18 Aug 2025","14-17 Sept. 2025","14-17 Sept. 2025","IEEE","IEEE Conferences"
"HPCAgentTester: a Multi-Agent LLM Approach for Enhanced HPC Unit Test Generation","R. Karanjai; L. Xu; W. Shi","Computer Science, University Of Houston; Computer Science, Kent State University; Computer Science, University Of Houston",2025 2nd IEEE/ACM International Conference on AI-powered Software (AIware),"19 Jan 2026","2025","","","213","222","Unit testing in High-Performance Computing (HPC) is critical but challenged by parallelism, complex algorithms, and diverse hardware. Traditional methods often fail to address non-deterministic behavior and synchronization issues in HPC applications. This paper introduces HPCAgentTester, a novel multi-agent Large Language Model (LLM) framework designed to automate and enhance unit test generation for HPC software utilizing OpenMP and MPI. HPCAgentTester employs a unique collaborative workflow where specialized LLM agents (Recipe Agent and Test Agent) iteratively generate and refine test cases through a critique loop. This architecture enables the generation of context-aware unit tests that specifically target parallel execution constructs, complex communication patterns, and hierarchical parallelism. We demonstrate HPCAgentTester's ability to produce compilable and functionally correct tests for OpenMP and MPI primitives, effectively identifying subtle bugs that are often missed by conventional techniques. Our evaluation shows that HPCAgentTester significantly improves test compilation rates and correctness compared to standalone LLMs, offering a more robust and scalable solution for ensuring the reliability of parallel software systems.","","979-8-3315-8269-2","10.1109/AIware69974.2025.00031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11334271","HPC;Large Language Models;MPI;MultiAgent Systems;OpenMP;Parallel Programming;Test Generation;Unit Testing","Large language models;Software algorithms;Collaboration;Parallel processing;Software systems;Hardware;Software reliability;Test pattern generators;Synchronization;Testing","","","","29","IEEE","19 Jan 2026","19-20 Nov. 2025","19-20 Nov. 2025","IEEE","IEEE Conferences"
"Intent-Driven Mobile GUI Testing with Autonomous Large Language Model Agents","J. Yoon; R. Feldt; S. Yoo","School of Computing, KAIST, Daejeon, Republic of Korea; Dept. of Computer Science & Engineering, Chalmers University, Gothenburg, Sweden; School of Computing, KAIST, Daejeon, Republic of Korea","2024 IEEE Conference on Software Testing, Verification and Validation (ICST)","27 Aug 2024","2024","","","129","139","GUI testing checks if a software system behaves as expected when users interact with its graphical interface, e.g., testing specific functionality or validating relevant use case scenarios. Currently, deciding what to test at this high level is a manual task since automated GUI testing tools target lower level adequacy metrics such as structural code coverage or activity coverage. We propose DroidAgent, an autonomous GUI testing agent for Android, for semantic, intent-driven automation of GUI testing. It is based on Large Language Models and support mechanisms such as long- and short-term memory. Given an Android app, DroidAgent sets relevant task goals and subsequently tries to achieve them by interacting with the app. Our empirical evaluation of DroidAgent using 15 apps from the Themis benchmark shows that it can set up and perform realistic tasks, with a higher level of autonomy. For example, when testing a messaging app, DroidAgent created a second account and added a first account as a friend, testing a realistic use case, without human intervention. On average, DroidAgent achieved 61% activity coverage, compared to 51 % for current state-of-the-art GUI testing techniques. Further, manual analysis shows that 317 out of the 547 autonomously created tasks are realistic and relevant to app functionalities, and also that DroidAgent interacts deeply with the apps and covers more features.","2159-4848","979-8-3503-0818-1","10.1109/ICST60714.2024.00020","National Research Foundation of Korea (NRF); Korean Government MSIT(grant numbers:RS-2023-00208998,2022-0-00995); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10638557","software testing;GUI testing;test automation;artificial intelligence;large language model","Software testing;Measurement;Automation;Large language models;Semantics;Manuals;Software systems","","14","","36","IEEE","27 Aug 2024","27-31 May 2024","27-31 May 2024","IEEE","IEEE Conferences"
"LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-Box Libraries","I. Hardgrove; J. D. Hastings","The Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA; The Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA",2025 Cyber Awareness and Research Symposium (CARS),"21 Jan 2026","2025","","","1","6","A fundamental problem in cybersecurity and computer science is determining whether a program is free of bugs and vulnerabilities. Fuzzing, a popular approach to discovering vulnerabilities in programs, has several advantages over alternative strategies, although it has investment costs in the form of initial setup and continuous maintenance. The choice of fuzzing is further complicated when only a binary library is available, such as the case of closed-source and proprietary software. In response, we introduce LibLMFuzz, a framework that reduces costs associated with fuzzing closed-source libraries by pairing an agentic Large Language Model (LLM) with a lightweight toolchain (disassembler/compiler/fuzzer) to autonomously analyze stripped binaries, plan fuzzing strategies, generate drivers, and iteratively self-repair build and runtime errors. Tested on four widely used Linux libraries, LibLMFuzz produced syntactically correct drivers for all 558 fuzzable API functions, achieving 100% API coverage with no human intervention. Across the 1601 synthesized drivers, 75.52% were nominally correct on first execution. The results show that LLM-augmented middleware holds promise in reducing the costs of fuzzing black-box components and provides a foundation for future research efforts. Future opportunities exist for research in branch coverage.","","979-8-3315-9628-6","10.1109/CARS67163.2025.11337309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11337309","LLM-augmented fuzzing;Autonomous target generation;Automated vulnerability discovery;API coverage;Black-box fuzzing;LLM fuzz-driver generation;Software security","Costs;Runtime;Linux;Large language models;Closed box;Fuzzing;Libraries;Maintenance;Middleware;Investment","","","","26","IEEE","21 Jan 2026","27-30 Oct. 2025","27-30 Oct. 2025","IEEE","IEEE Conferences"
"Towards Autonomous Testing Agents via Conversational Large Language Models","R. Feldt; S. Kang; J. Yoon; S. Yoo",Chalmers University of Technology; KAIST; KAIST; KAIST,2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE),"8 Nov 2023","2023","","","1688","1693","Software testing is an important part of the development cycle, yet it requires specialized expertise and substantial developer effort to adequately test software. Recent discoveries of the capabilities of large language models (LLMs) suggest that they can be used as automated testing assistants, and thus provide helpful information and even drive the testing process. To highlight the potential of this technology, we present a taxonomy of LLM-based testing agents based on their level of autonomy, and describe how a greater level of autonomy can benefit developers in practice. An example use of LLMs as a testing assistant is provided to demonstrate how a conversational framework for testing can help developers. This also highlights how the often criticized “hallucination” of LLMs can be beneficial for testing. We identify other tangible benefits that LLM-driven testing agents can bestow, and also discuss potential limitations.","2643-1572","979-8-3503-2996-4","10.1109/ASE56229.2023.00148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10298360","software testing;machine learning;large language model;artificial intelligence, test automation","Software testing;Automation;Taxonomy;Oral communication;Drives;Middleware;Testing","","28","","36","IEEE","8 Nov 2023","11-15 Sept. 2023","11-15 Sept. 2023","IEEE","IEEE Conferences"
"LLM-Driven Smart Test Case Generation for Scalable Software Testing","K. Kanagaraj; D. Handa; K. K. Nikhil; S. Duvarakanath; S. M.","Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, India; Department of Computer Science and Engineering, Amrita School of Computing, Bengaluru, India","2025 2nd International Conference on Software, Systems and Information Technology (SSITCON)","22 Jan 2026","2025","","","1","6","Software testing is vital to modern development; however, traditional test case generation remains limited by imprecision, heavy manual intervention, and a lack of scalability. This study proposes a robust framework that integrates Large Language Models (LLMs) with multi-agent systems to generate fully automated, end-to-end test cases. By combining Deep Learning with Chain-of-Thought reasoning, the framework intelligently analyzes back-end APIs and front-end UIs, producing context-aware and comprehensive test suites. The evaluation of the system demonstrated a high-test success rate of 91.6 % and an average code coverage of 85.3 % in diverse applications. This study offers a much greater degree of adaptability to new requirements with minimal intervention while maintaining high reliability and performance qualities. These facts make it attractive for enterprise environments, where it can speed up testing with much greater precision, scaling, and enterprise readiness. Hence, the framework stands for an end-to-end solution for next-generation regression automation.","","979-8-3315-2623-8","10.1109/SSITCON66133.2025.11342080","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11342080","LLM;Multi-Agent Systems;Testcase Generation;System Testing;CI/CD","Software testing;System testing;Codes;Automation;Manuals;Software systems;Software reliability;Stakeholders;Multi-agent systems;Software development management","","","","15","IEEE","22 Jan 2026","17-18 Oct. 2025","17-18 Oct. 2025","IEEE","IEEE Conferences"
"NIODebugger: A Novel Approach to Repair Non-Idempotent-Outcome Tests with LLM-Based Agent","K. Ke","University of Illinois Urbana-Champaign, Urbana, IL, USA",2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),"23 Jun 2025","2025","","","1014","1025","Flaky tests, characterized by inconsistent results across repeated executions, present significant challenges in software testing, especially during regression testing. Recently, there has been emerging research interest in non-idempotentoutcome (NIO) flaky tests-tests that pass on the initial run but fail on subsequent executions within the same environment. Despite progress in utilizing Large Language Models (LLMs) to address flaky tests, existing methods have not tackled NIO flaky tests. The limited context window of LLMs restricts their ability to incorporate relevant source code beyond the test method itself, often overlooking crucial information needed to address state pollution, which is the root cause of NIO flakiness. This paper introduces NIODebugger, the first framework to utilize an LLM-based agent to repair flaky tests. NIODebugger features a three-phase design: detection, exploration, and fixing. In the detection phase, dynamic analysis collects stack traces and custom test execution logs from multiple test runs, which helps in understanding accumulative state pollution. During the exploration phase, the LLM-based agent provides instructions for extracting relevant source code associated with test flakiness. In the fixing phase, NIODebugger repairs the tests using the information gathered from the previous phases. NIODebugger can be integrated with multiple LLMs, achieving patching success rates ranging from 11.63% to 58.72%. Its best-performing variant, NIODebugger-GPT-4, successfully generated correct patches for 101 out of 172 previously unknown NIO tests across 20 largescale open-source projects. We submitted pull requests for all generated patches; 58 have been merged, only 1 was rejected, and the remaining 42 are pending. The Java implementation of NIODebugger is provided as a Maven plugin accessible at https://github.com/kaiyaok2/NIOInspector.","1558-1225","979-8-3315-0569-1","10.1109/ICSE55347.2025.00226","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11029812","flaky tests;llm-based agent;software testing","Software testing;Java;Pollution;Source coding;Large language models;Maintenance engineering;Feature extraction;Distance measurement;Software engineering","","1","","58","IEEE","23 Jun 2025","26 April-6 May 2025","26 April-6 May 2025","IEEE","IEEE Conferences"
"Lockheed Martin AI Factory: Generative AI and MLOps for Engineering, Enterprise and Edge","M. Maybury; G. Forrest; D. O'Donnell","Technology and Strategic Innovation Lockheed Martin, Chelmsford, MA, USA; AI Foundations Lockheed Martin AI Center, Shelton, CT, USA; Astris AI, Westport, CT, USA",2025 IEEE International Conference on AI and Data Analytics (ICAD),"20 Aug 2025","2025","","","1","7","This article reports on the rapid creation and deployment at scale of hundreds of Large Language Model (LLM) applications, highlighting several across enterprise, engineering and edge use cases. This outcome was accelerated by the creation of an open architecture, secure and scalable generative AI Factory. An extensible platform, AI Factory empowers thousands of developers and over 50,000 end users across a diverse set of data types and use cases throughout our global enterprise. This evolvable approach reveals how to affordably deploy generative AI to create value securely at scale.","","979-8-3315-2472-2","10.1109/ICAD65464.2025.11114065","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11114065","Generative AI;AI Factory;LLMs;scale;security","Data analysis;Generative AI;Large language models;Production facilities;Security","","","","20","IEEE","20 Aug 2025","24-24 June 2025","24-24 June 2025","IEEE","IEEE Conferences"
"AI-Powered Multi-Agent Framework for Automated Unit Test Case Generation: Enhancing Software Quality through LLM’s","A. Garlapati; M. N. V. Satya Sai Muni Parmesh; Savitha; J. S","Watsonx Client Engineering, IBM, Bangalore; Watsonx Client Engineering, IBM, Bangalore; Watsonx Client Engineering, IBM, Bangalore; Watsonx Client Engineering, IBM, Bangalore",2024 5th IEEE Global Conference for Advancement in Technology (GCAT),"20 Mar 2025","2024","","","1","5","Recent years have witnessed an enormous rise in the design, repair and the enhancement of software automation tests. The reliability of program’s unit testing has major impact on its overall performance. The anticipated influence of Artificial Intelligence advancements on test automation methodologies are significant. Many studies on automated testing implicitly assume that the test results are deterministic, means that similar tests faults remain same. The precision of software is largely ensured by unit testing. But writing unit tests manually is a time-consuming process, which leads us to drive into ""Automation Analysis"". Recent years comprised the application of Large Language Models (LLM’s) in numerous fields related to software development, especially the automated creation of unit testing.However, these frameworks require more instructions, or few shot learnings on sample tests that already exist. This research provides a comprehensive empirical assessment of the efficiency of LLM’s for automating unit testing production, with no need for further manual analysis. The method we employ is put into practice for test cases, an adaptable Agents and LLM-based testing framework that evaluates test cases generated, by reviewing and re-writing them in different phases. Evaluation of this test cases was done by using mistral-large LLM Model. The analysis results that developed acquired an overall coverage of 100% for code given. Finally, to enhance the typical evaluation, this research suggests and concludes that LLMs, can be successfully incorporated into present practices, through adaptative instructions and improvements.","","979-8-3503-7668-5","10.1109/GCAT62922.2024.10923987","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10923987","Large Language Models - LLM’s;Manual Testing;Artificial Intelligence;Automation;Agents;Unit Tests","Java;Codes;Automation;Large language models;Manuals;Switches;Writing;Software reliability;Standards;Testing","","4","","15","IEEE","20 Mar 2025","4-6 Oct. 2024","4-6 Oct. 2024","IEEE","IEEE Conferences"
"IntelliTest: An Intelligent Framework for Agentic Functional Test Generation Using Multimodal Data and Domain Knowledge","A. S. Tiwari; S. Ganesh Nutan Dev C; P. M. Patole; G. Ponnamreddy; S. Chinthalapudi; D. P. Kattamanchi","Samsung Semiconductor India Research, Bangalore, India; Samsung Semiconductor India Research, Bangalore, India; Samsung Semiconductor India Research, Bangalore, India; Samsung Semiconductor India Research, Bangalore, India; Samsung Semiconductor India Research, Bangalore, India; Samsung Semiconductor India Research, Bangalore, India",2025 IEEE Future Networks World Forum (FNWF),"2 Jan 2026","2025","","","1","6","IntelliTest is an end-to-end, locally deployable framework that automates functional test generation and selection for complex embedded systems from two input modes: Software Change Artifacts (SCAs)—multimodal changelist data combining code diffs with textual metadata—and Natural-Language Queries (NLQs) for direct test requests. It employs a domainagnostic ontology defining procedural semantics, compiled into a structured procedural database and a specification knowledge graph for retrieval-augmented reasoning. The dual-agent architecture—Context-Analysis-and-Scoping Agent (CASA) and Constrained-Testcase-Synthesis Agent (CTSA)—interprets SCAs or NLQs, validates functionalities through ontology-grounded databases, and synthesizes constraint-compliant sequences. Dynamic coverage databases use greedy set-cover selection and cross-impact expansion to expose cousin bugs in adjacent modules. Human-in-the-loop feedback refines ontology instantiations. Deployed locally for data-security compliance, IntelliTest was validated on commercial modem firmware (>50,000 files, >250,000 functions), achieving 95% functionality identification, 92% code-change coverage, 90% constraint satisfaction, and a five-fold reduction in generation time, shrinking regression suites by 40–60% while maintaining comprehensive coverage","2770-7679","979-8-3315-9193-9","10.1109/FNWF66845.2025.11317278","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11317278","Automated Functional Testing;LLM Agents;multi-agent systems;ontology-driven generation;dual-agent frameworks;retrieval-augmented generation","Accuracy;Databases;Semantics;Knowledge graphs;Ontologies;Modems;Software;Test pattern generators;Microprogramming;Testing","","","","16","IEEE","2 Jan 2026","10-12 Nov. 2025","10-12 Nov. 2025","IEEE","IEEE Conferences"
"Multi-Agent Auditing for Smart Contracts*","Y. Ding; J. Yu; A. Twabi; L. Zhang; T. Kondo; H. Sato","Hiroshima University, Higashihiroshima, Japan; The University of Tokyo, Tokyo, Japan; Hiroshima University, Higashihiroshima, Japan; The University of Tokyo, Tokyo, Japan; Hiroshima University, Higashihiroshima, Japan; National Institute of Informatics, Tokyo, Japan",2025 9th International Symposium on Computer Science and Intelligent Control (ISCSIC),"26 Jan 2026","2025","","","1","7","Smart contracts underpin contemporary decentralized systems, yet their immutability and perpetual execution amplify the consequences of latent defects. Despite progress in manual audits, static analysis, fuzzing, and formal verification, auditors face a widening gap between the scalability and desired assurance due to limited automation capability. Recent large language models (LLMs) with tool-use capabilities promise greater automation, but monolithic single-agent auditors struggle with coverage, robustness, and reproducibility. Motivated by addressing these issues, we propose Multi-Agent Auditing (MAA), a framework that coordinates a team of tool-grounded agents through a constrained protocol that privileges verifiable artifacts. Besides, we mechanize an LLM-assisted orchestration mechanism and a shared knowledge base to coordinate a set of agents specialized in sophisticated testing approaches to produce budget-aware and evidence-centric audit results. Furthermore, we present the experiment results showing that MAA outperforms singleLLM auditors and provide empirical insights into LLM-backend selection.","","979-8-3315-6593-0","10.1109/ISCSIC67494.2025.11352002","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11352002","multi-agent system;smart contract;large language model;agent orchestration;software testing","Automation;Large language models;Scalability;Smart contracts;Knowledge based systems;Static analysis;Manuals;Robustness;Reproducibility of results;Multi-agent systems","","","","32","IEEE","26 Jan 2026","26-28 Sept. 2025","26-28 Sept. 2025","IEEE","IEEE Conferences"
"An Agentic Reasoning-Based Feedback System for Programming Assignments","N. A. A. Sulaiman; H. Haron; N. M. Mahfuz; N. A. M. Saat; S. N. Daud; S. Alias","Sustainable Information Technology & Innovation Center, Faculty of Engineering, Built Environment and Information Technology (FOEBEIT), SEGi University, Selangor, Malaysia; Sustainable Information Technology & Innovation Center, Faculty of Engineering, Built Environment and Information Technology (FOEBEIT), SEGi University, Selangor, Malaysia; Sustainable Information Technology & Innovation Center, Faculty of Engineering, Built Environment and Information Technology (FOEBEIT), SEGi University, Selangor, Malaysia; Sustainable Information Technology & Innovation Center, Faculty of Engineering, Built Environment and Information Technology (FOEBEIT), SEGi University, Selangor, Malaysia; Centre for Network Security and IoT, Faculty of Engineering, Built Environment and Information Technology (FOEBEIT), SEGi University, Selangor, Malaysia; Centre for Network Security and IoT, Faculty of Engineering, Built Environment and Information Technology (FOEBEIT), SEGi University, Selangor, Malaysia","2025 IEEE 11th International Conference on Computing, Engineering and Design (ICCED)","13 Jan 2026","2025","","","1","6","This study introduces Explain-then-Grade, an automated feedback framework designed for programming lab assignments using agent reasoning and large language models (LLMs). Unlike conventional auto-graders, which provide marks directly and general feedback, the proposed framework requires the agent to explain detected errors prior to assigning marks, thereby enhancing pedagogical value and transparency. The framework integrates sandboxed execution, on-the-fly test generation, and structured, stepwise explanatory reasoning, ensuring that students receive constructive, rubric-aligned feedback. To evaluate its effectiveness, the system was applied to anonymized submissions from a Data Mining module and complemented with open-source student code repositories. Performance was benchmarked against classic unit test-based auto-graders and LLM-only grading models, using five dimensions: grading accuracy, explanation quality, error coverage, and efficiency. Results demonstrate that Explain-then-Grade achieved higher grading reliability ($93 \%$ accuracy, $\kappa=0.85$), superior explanation quality (4.4/5), broader error coverage ($83.7 \%$), and substantial time savings ($67 \%$). These outcomes highlight its potential to support both traditional and open and distance learning (ODL) contexts by shifting automated assessment from mere evaluation toward formative, feedback-driven learning. The study establishes a structured agentic reasoning pipeline for reproducible and pedagogically aligned automated grading.","2767-7826","979-8-3315-4520-8","10.1109/ICCED68324.2025.11324743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11324743","Agent Reasoning;Automated Grading;Large Language Model (LLM);Trustworthy AI in Education","Computer aided instruction;Accuracy;Codes;Large language models;Pipelines;Cognition;Test pattern generators;Reliability;Data mining;Programming profession","","","","16","IEEE","13 Jan 2026","13-15 Nov. 2025","13-15 Nov. 2025","IEEE","IEEE Conferences"
"Multi-Agent Fuzzy Reinforcement Learning With LLM for Cooperative Navigation of Endovascular Robotics","T. Yao; Y. Xu; H. Wang; X. Qiu; K. Althoefer; P. Qi","Department of Control Science and Engineering, College of Electronic and Information Engineering, Shanghai Institute of Intelligent Science and Technology, Tongji University, Shanghai, China; College of Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Control Science and Engineering, College of Electronic and Information Engineering, Shanghai Institute of Intelligent Science and Technology, Tongji University, Shanghai, China; School of Electronic and Electrical Engineering, Shanghai University of Engineering Science, Shanghai, China; Centre for Advanced Robotics @ Queen Mary, School of Engineering and Materials Science, Queen Mary University of London, London, U.K.; Department of Control Science and Engineering, College of Electronic and Information Engineering, Shanghai Institute of Intelligent Science and Technology, Tongji University, Shanghai, China",IEEE Transactions on Fuzzy Systems,"","2025","PP","99","1","11","Endovascular interventions require precise, cooperative control of multiple instruments, such as guidewires and catheters, to navigate complex vascular anatomies. Current robotic systems, reliant on leader-follower control, depend heavily on operator expertise and lack intelligence. Learning-based methods, often limited to single-instrument control, fall short in complex clinical scenarios requiring multi-instrument coordination. This study proposes a Multi-Agent Fuzzy Reinforcement Learning (MAFRL) framework, guided by large language models (LLMs), for task-level autonomous, cooperative navigation in endovascular robotics. LLMs provide procedural priors and context-aware policy guidance, enabling adaptive decision-making for collaborative guidewire and catheter agents. Central to the framework, fuzzy reinforcement learning mitigates LLM-induced uncertainties by adaptively embedding clinical constraints into reward functions, ensuring strict adherence to procedural safety and precise alignment with the complexities of real-world endovascular interventions. Validated in a 3D vascular simulation, this approach achieves superior navigation performance and procedural efficiency compared to conventional methods, underscoring the transformative potential of fuzzy reinforcement learning in advancing LLM-guided MARL for endovascular robotics.","1941-0034","","10.1109/TFUZZ.2025.3585934","National Key Research and Development Program of China(grant numbers:2023YFB4705200); National Natural Science Foundation of China(grant numbers:62273257); Open Project Fund of State Key Laboratory of Cardiovascular Diseases(grant numbers:2024SKL-TJ002); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11078928","Autonomous navigation;endovascular procedure;fuzzy reinforcement learning;large language models;learning-based control","Navigation;Catheters;Robots;Robot kinematics;Reinforcement learning;Fuzzy systems;Uncertainty;Instruments;Decision making;Anatomy","","5","","","IEEE","14 Jul 2025","","","IEEE","IEEE Early Access Articles"
"Agent for User: Testing Multi - User Interactive Features in TikTok","S. Feng; C. Du; H. Liu; Q. Wang; Z. Lv; G. Huo; X. Yang; C. Chen","Monash University, Australia; Jilin University, China; Jilin University, China; Jilin University, China; Bytedance, China; Bytedance, China; Bytedance, China; Technical University of Munich, Germany",2025 IEEE/ACM 47th International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP),"20 Aug 2025","2025","","","57","68","TikTok, a widely-used social media app boasting over a billion monthly active users, requires effective app quality assurance for its intricate features. Feature testing is crucial in achieving this goal. However, the multi-user interactive features within the app, such as live streaming, voice calls, etc., pose significant challenges for developers, who must handle simultaneous device management and user interaction coordination. To address this, we introduce a novel multi-agent approach, powered by the Large Language Models (LLMs), to automate the testing of multi-user interactive app features. In detail, we build a virtual device farm that allocates the necessary number of devices for a given multi-user interactive task. For each device, we deploy an LLM-based agent that simulates a user, thereby mimicking user interactions to collaboratively automate the testing process. The evaluations on 24 multi-user interactive tasks within the TikTok app, showcase its capability to cover 75% of tasks with 85.9 % action similarity and offer 87 % time savings for developers. Additionally, we have also integrated our approach into the real-world TikTok testing platform, aiding in the detection of 26 multi-user interactive bugs.","2832-7659","979-8-3315-3685-5","10.1109/ICSE-SEIP66354.2025.00011","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11121721","multi-agent LLMs;multi-user interactive feature;android app testing","Software testing;Video on demand;Social networking (online);Computer bugs;Software;Web sites;Time factors;Servers;Testing;Software engineering","","","","59","IEEE","20 Aug 2025","27 April-3 May 2025","27 April-3 May 2025","IEEE","IEEE Conferences"
"Try-Then-Eval: Equipping an LLM-based Agent with a Two-Phase Mechanism to Solve Computer Tasks","D. Cao; P. Nguyen; V. Le; L. Nguyen; V. Nguyen","Faculty of Information Technology, University of Science, Ho Chi Minh City, Vietnam; Faculty of Information Technology, University of Science, Ho Chi Minh City, Vietnam; Faculty of Computer Science, University of Information Technology, Ho Chi Minh City, Vietnam; Faculty of Information Technology, University of Science, Ho Chi Minh City, Vietnam; Faculty of Information Technology, University of Science, Ho Chi Minh City, Vietnam","2024 IEEE International Conference on Systems, Man, and Cybernetics (SMC)","20 Jan 2025","2024","","","1224","1229","Building an autonomous intelligent agent capable of carrying out web automation tasks from descriptions in natural language offers a wide range of applications, including software testing, virtual assistants, and task automation in general. However, recent studies addressing this problem often require manually constructing of prior human demonstrations. In this paper, we approach the problem by leveraging the idea of reinforcement learning (RL) with the two-phase mechanism to form an agent using LLMs for automating computer tasks without relying on human demonstrations. We evaluate our LLM-based agent using the MiniWob++ dataset of web-based application tasks, showing that our approach achieves 85% success rate without prior demonstrations. The results also demonstrate the agent's capability of self-improvement through training.","","978-1-6654-1020-5","10.1109/SMC54092.2024.10831260","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10831260","","Training;Software testing;Automation;Virtual assistants;Supervised learning;Natural languages;Reinforcement learning;Planning;Intelligent agents;Cybernetics","","","","25","IEEE","20 Jan 2025","6-10 Oct. 2024","6-10 Oct. 2024","IEEE","IEEE Conferences"
"LLMs in Debate: Does Arguing Make Them Better at Detecting Metamorphic Relations?","D. B. Bose; Y. B. Alebachew; C. Brown","Department of Computer Science, Virginia Tech; Department of Computer Science, Virginia Tech; Department of Computer Science, Virginia Tech",2025 40th IEEE/ACM International Conference on Automated Software Engineering Workshops (ASEW),"19 Jan 2026","2025","","","43","50","Large Language Models (LLMs) are transforming software engineering, including mobile Augmented Reality (AR) applications. AR software behavior often depends on dynamic environmental factors, making it difficult to use conventional testing and verification approaches. Metamorphic Testing (MT) offers an alternative by assessing whether expected transformations hold across varied conditions. However, there is limited work exploring how well LLMs can detect these transformations-Metamorphic Relations (MRs)-in applications. We propose a stability-driven evaluation framework that examines whether LLMs consistently apply MRs across rephrasings. Our study finds that StarCoder and CodeLlama exhibit higher stability in MR identification compared to the general-purpose model Gemma. Additionally, we use a multi-agent debate framework to investigate whether combining multiple perspectives improves consistency in MR identification. The debate mechanism reduces MR inconsistencies, leading to more stable MR identification across all MRs. While debate helps stabilize MR identification, our evaluation against humanlabeled ground truth reveals that stability alone does not always correlate with correctness. Some models maintain stable yet incorrect predictions(CodeLlama), whereas debate enhances both consistency and correctness alignment, making LLM reasoning more reliable. This work contributes a method to evaluate LLMs in the absence of ground truth, establishing stability as a metric for assessing model reliability. Applying a multi-agent debate framework offers a promising approach to enhancing LLM reliability, especially in contexts where the ground truth is elusive.","2151-0849","979-8-3315-8503-7","10.1109/ASEW67777.2025.00019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11334553","Large language models;Metamorphic testing;Augmented Reality (AR);Multi-Agent Debate;Stability Evaluation","Software testing;Large language models;Source coding;Predictive models;Stability analysis;Cognition;Software;Software reliability;Augmented reality;Software engineering","","","","48","IEEE","19 Jan 2026","16-20 Nov. 2025","16-20 Nov. 2025","IEEE","IEEE Conferences"
"Leveraging Large Language Models for Dynamic Scenario Building targeting Enhanced Cyber-threat Detection and Security Training","C. Marantos; S. Evangelatos; E. Veroni; G. Lalas; K. Chasapas; I. T. Christou; P. Lappas","Research & Innovation Development Department, Netcompany-Intrasoft S.A., Luxembourg, Luxembourg; Research & Innovation Development Department, Netcompany-Intrasoft S.A., Luxembourg, Luxembourg; Research & Innovation Development Department, Netcompany-Intrasoft S.A., Luxembourg, Luxembourg; Research & Innovation Development Department, Netcompany-Intrasoft S.A., Luxembourg, Luxembourg; Research & Innovation Development Department, Netcompany-Intrasoft S.A., Luxembourg, Luxembourg; Research & Innovation Development Department, Netcompany-Intrasoft S.A., Luxembourg, Luxembourg; Research & Innovation Development Department, Netcompany-Intrasoft S.A., Luxembourg, Luxembourg",2024 IEEE International Conference on Big Data (BigData),"16 Jan 2025","2024","","","2779","2788","As cybercrime is becoming increasingly sophisticated, effective cybersecurity is crucial to safeguard digital assets and protect critical infrastructures from emerging threats. Several security applications exploit recent advances in (Big) data analysis and Artificial Intelligence (AI) to prevent and respond to malicious activities. Towards this direction, supervised and unsupervised Machine Learning (ML) methods are used to detect anomalies or reveal patterns that may indicate potential threats. However, the successful implementation of these technologies requires security practitioners to undergo specialized training to fully understand and use AI-driven tools and data analytics. On the other hand, AI models themselves are vulnerable to a variety of cyber threats, which can compromise their training data and learning processes. To ensure the safe operation of these systems, especially when deployed in adversarial environments, it is crucial to create novel AI adversarial algorithms and models that are resilient against diverse security threats. This work presents a conceptual framework based on Large Language Models (LLMs) supported by a Multi-Agent layer for training of security practitioners in various advanced technologies and enhance ML models ability to detect and respond to emerging cyber threats effectively.","2573-2978","979-8-3503-6248-0","10.1109/BigData62323.2024.10825681","Horizon Europe; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10825681","Scenario Building;LLM;Adversarial Learning;Data Augmentation;Explainable AI","Training;Explainable AI;Large language models;Buildings;Training data;Transforms;Big Data;Data models;Security;Multi-agent systems","","2","","30","IEEE","16 Jan 2025","15-18 Dec. 2024","15-18 Dec. 2024","IEEE","IEEE Conferences"
"A Fully Automated Agent for End-to-End Code Translation and Validation","E. Erer; A. Bozanta; T. Aytac; A. Basar","Computer Engineering, Bogazici University, Istanbul, Turkey; Management Information Systems, Bogazici University, Istanbul, Turkey; Data Science, AI4U, Istanbul, Turkey; Data Science Lab, Toronto Metropolitan University, Toronto, Canada",2025 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM),"12 Jan 2026","2025","","","324","330","Background: Software migration across programming languages is a critical yet labor-intensive task, often requiring deep code understanding and manual intervention. Aims: In this study, we aim to develop a fully automated agent for end-to-end code translation and validation. Method: First, we generate code comments from Java source code using various large language models (LLMs) to enhance code comprehension and facilitate cross-language translation. Second, leveraging these AI-generated comments, we automatically generate equivalent C# code, demonstrating the potential of AI in software migration and interoperability. Third, we complete both Java and generated C# code and prepare them to execute. Fourth, we apply automated unit testing to assess functional correctness and ensure the reliability of AI-generated code. Results: Our results show that a fully automated LLM agent may effectively bridge programming languages with minimal human input. This approach opens new possibilities for scalable, AIdriven software modernization and cross-platform development. Conclusions: We recommend that such an LLM agent should be used to support human experts during the generation of reliable and correct code.","","979-8-3315-9147-2","10.1109/ESEM64174.2025.00058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11323478","code generation;code summarization;code translation;code completion;automated unit testing","Java;Computer languages;Codes;Translation;Source coding;Manuals;Software;C# languages;Software reliability;Testing","","","","25","IEEE","12 Jan 2026","2-3 Oct. 2025","2-3 Oct. 2025","IEEE","IEEE Conferences"
"A Fully Automated Agent for End-to-End Code Translation and Validation","E. Erer; A. Bozanta; T. Aytac; A. Basar","Computer Engineering, Bogazici University, Istanbul, Turkey; Management Information Systems, Bogazici University, Istanbul, Turkey; Data Science, AI4U, Istanbul, Turkey; Data Science Lab, Toronto Metropolitan University, Toronto, Canada",2025 IEEE International Conference on Collaborative Advances in Software and COmputiNg (CASCON),"23 Jan 2026","2025","","","134","141","Migration of software across programming languages is a critical yet labor-intensive task, often requiring deep code understanding and manual intervention. In this study, we develop a fully automated agent for end-to-end code translation and validation. First, we generate code comments from Java source code using various large language models (LLMs) to enhance code comprehension and facilitate cross-language translation. Second, leveraging these AI-generated comments, we automatically generate equivalent C# code, demonstrating the potential of AI in software migration and interoperability. Third, we complete both Java and generated C# code and prepare them to execute. Fourth, we apply automated unit testing to assess functional correctness and ensure the reliability of AI-generated code. Our results show that a fully automated LLM agent may be effective in bridging programming languages with human-in-the-loop. This approach opens new possibilities for scalable, AIdriven software modernization and cross-platform development. We recommend that such an LLM agent should be used in tandem with human experts during the generation of a reliable and correct code.","","979-8-3315-9948-5","10.1109/CASCON66301.2025.00128","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11344486","code generation;code summarization;code translation;code completion;automated unit testing","Measurement;Java;Computer languages;Codes;Translation;Source coding;Software;C# languages;Software reliability;Testing","","","","25","IEEE","23 Jan 2026","10-13 Nov. 2025","10-13 Nov. 2025","IEEE","IEEE Conferences"
"Human-In-The-Loop Software Development Agents: Challenges and Future Directions","J. Pasuksmit; W. Takerngsaksiri; P. Thongtanunam; C. Tantithamthavorn; R. Zhang; S. Wang; F. Jiang; J. Li; E. Cook; K. Chen; M. Wu","Atlassian, Australia; Monash University, Australia; The University of Melbourne, Australia; Monash University, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia; Atlassian, Australia",2025 IEEE/ACM 22nd International Conference on Mining Software Repositories (MSR),"13 Jun 2025","2025","","","756","757","Multi-agent LLM-driven systems for software development are rapidly gaining traction, offering new opportunities to enhance productivity. At Atlassian, we deployed Human-in-the-Loop Software Development Agents to resolve Jira work items and evaluated the generated code quality using functional correctness testing and GPT-based similarity scoring. This paper highlights two major challenges: the high computational costs of unit testing and the variability in LLM-based evaluations. We also propose future research directions to improve evaluation frameworks for Human-In-The-Loop software development tools.","2574-3864","979-8-3315-0183-9","10.1109/MSR66628.2025.00112","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11025667","hula;atlassian;llm;human-in-the-loop;jira;code-generation","Productivity;Codes;Human in the loop;Software;Computational efficiency;Data mining;Software development management;Testing","","1","","6","IEEE","13 Jun 2025","28-29 April 2025","28-29 April 2025","IEEE","IEEE Conferences"
"Autonomous Penetration Testing: Solving Capture-the-Flag Challenges with LLMs","I. Bakker; J. Hastings","The Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA; The Beacom College of Computer and Cyber Sciences, Dakota State University, Madison, SD, USA",2025 Cyber Awareness and Research Symposium (CARS),"21 Jan 2026","2025","","","1","6","This study evaluates the ability of GPT-4o to au-tonomously solve beginner-level offensive security tasks by con-necting the model to OverTheWire's Bandit capture-the-flag game. Of the 25 levels that were technically compatible with a single-command SSH framework, GPT-4o solved 18 unaided and another two after minimal prompt hints for an overall 80% success rate. The model excelled at single-step challenges that involved Linux filesystem navigation, data extraction or decoding, and straightforward networking. The approach often produced the correct command in one shot and at a human-surpassing speed. Failures involved multi-command scenarios that required persistent working directories, complex network reconnaissance, daemon creation, or interaction with non-standard shells. These limitations largely reflect the architectural harness choices rather than a lack of general exploit knowledge. The results demonstrate that large language models (LLMs) can automate a substantial portion of novice penetration-testing workflow, potentially lowering the expertise barrier for attackers and offering productivity gains for defenders who use LLMs as rapid reconnaissance aides. Further, the unsolved tasks reveal specific areas where secure-by-design environments might frustrate simple LLM -driven attacks, informing future hardening strategies. Beyond offensive cyberse-curity applications, results suggest the potential to integrate LLMs into cybersecurity education as practice aids.","","979-8-3315-9628-6","10.1109/CARS67163.2025.11337515","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11337515","Large Language Models (LLMs);Offensive Cy-bersecurity;Capture-the-Flag (CTF) Challenges;Penetration Testing Automation","Productivity;Navigation;Linux;Large language models;Education;Games;Reconnaissance;Data models;Decoding;Penetration testing","","","","20","IEEE","21 Jan 2026","27-30 Oct. 2025","27-30 Oct. 2025","IEEE","IEEE Conferences"
"Seeing is Believing: Vision-Driven Non-Crash Functional Bug Detection for Mobile Apps","Z. Liu; C. Li; C. Chen; J. Wang; M. Chen; B. Wu; Y. Wang; J. Hu; Q. Wang","State Key Laboratory of Complex System Modeling and Simulation Technology, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Complex System Modeling and Simulation Technology, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Technical University of Munich, Munich, Germany; State Key Laboratory of Complex System Modeling and Simulation Technology, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Complex System Modeling and Simulation Technology, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Complex System Modeling and Simulation Technology, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Complex System Modeling and Simulation Technology, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Complex System Modeling and Simulation Technology, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Complex System Modeling and Simulation Technology, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,"11 Dec 2025","2025","51","12","3452","3466","Mobile app GUI (Graphical User Interface) pages now contain rich visual information, with the visual semantics of each page helping users understand the application logic. However, these complex visual and functional logics present new challenges to software testing. Existing automated GUI testing methods, constrained by the lack of reliable testing oracles, are limited to detecting crash bugs with obvious abnormal signals. Consequently, many non-crash functional bugs, ranging from unexpected behaviors to logical errors, often evade detection by current techniques. While these non-crash functional bugs can exhibit visual cues that serve as potential testing oracles, they often entail a sequence of screenshots, and detecting them necessitates an understanding of the operational logic among GUI page transitions, which is challenging traditional techniques. Considering the remarkable performance of Multimodal Large Language Models (MLLM) in visual and language understanding, this paper proposes VisionDroid, a novel vision-driven, multi-agent collaborative automated GUI testing approach for detecting non-crash functional bugs. It comprises three agents: Explorer, Monitor, and Detector, to guide the exploration, oversee the testing progress, and spot issues. We also address several challenges, i.e., aligning visual and textual information for MLLM input, achieving functionality-oriented exploration, and inferring test oracles for non-crash bugs, to enhance the performance of functionality bug detection. We evaluate VisionDroid on 590 non-crash bugs and compare it with 12 baselines, it can achieve more than 14%-112% and 108%-147% boost in average recall and precision compared with the best baseline. The ablation study further proves the contribution of each module. Moreover, VisionDroid identifies 43 unknown bugs on Google Play, of which 31 have been fixed.","1939-3520","","10.1109/TSE.2025.3614469","National Natural Science Foundation of China(grant numbers:62402483,62232016,62072442,62272445,62402484); Basic Research Program of ISCAS(grant numbers:ISCAS-JCZD-202304); Major Program of ISCAS(grant numbers:ISCAS-ZD-202302,ISCAS-ZD-202401); Innovation Team 2024 ISCAS(grant numbers:2024-66); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11181197","Multimodal large language model;android app;non-crash bugs","Computer bugs;Graphical user interfaces;Testing;Visualization;Detectors;Monitoring;Logic;Data mining;Semantics;Annotations","","","","66","IEEE","26 Sep 2025","Dec. 2025","","IEEE","IEEE Journals"
"ChipMnd: LLMs for Agile Chip Design","F. Firouzi; D. Z. Pan; J. Gu; B. Farahani; J. Chaudhuri; Z. Yin; P. Ma; P. Domanski; K. Chakrabarty",Arizona State University; University of Texas at Austin; Arizona State University; Shahid Beheshti University; Arizona State University; Arizona State University; Arizona State University; Arizona State University; Arizona State University,2025 IEEE 43rd VLSI Test Symposium (VTS),"10 Jun 2025","2025","","","1","10","The increasing complexity of semiconductor design, along with stringent performance, power, and time-to-market requirements, has outpaced the capabilities of traditional Electronic Design Automation (EDA) methodologies. Conventional design workflows rely on manual intervention for critical tasks such as hardware description, synthesis optimization, and verification, leading to inefficiencies and scalability limitations. Large Language Models (LLMs) present a transformative approach by automating key stages of the design pipeline, enabling intelligent synthesis tuning, test generation, and security analysis. This paper introduces ChipMind, an LLM-driven framework comprising specialized agents and modules for digital and analog chip design. ChipMind integrates AI-driven methodologies to enhance design efficiency, accelerate prototyping, and optimize key design trade-offs, thereby addressing fundamental challenges in modern semiconductor development.","2375-1053","979-8-3315-2144-8","10.1109/VTS65138.2025.11022936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11022936","AI for chip design;Large Language Models (LLMs);Electronic Design Automation (EDA);hardware security","Design automation;Design methodology;Scalability;Large language models;Hardware security;Very large scale integration;Complexity theory;Test pattern generators;Chip scale packaging;Optimization","","3","","56","IEEE","10 Jun 2025","28-30 April 2025","28-30 April 2025","IEEE","IEEE Conferences"
"Research on Multi-Model Fusion Machine Learning Demand Intelligent Forecasting System in Cloud Computing Environment","J. Huang","EC2 Core Platform, Amazon.Com Services LLC, Seattle, United States",2025 2nd International Conference on Intelligent Algorithms for Computational Intelligence Systems (IACIS),"5 Nov 2025","2025","","","1","7","Background: Large language models (LLMs) are increasingly being used for automated unit test generation, but reported performance varies across tasks and datasets, and key aspects such as assertion plausibility and target coverage are not well understood. Methods: We perform a structured evaluation of LLM-based test generation on recent benchmarks and settings, summarizing research results in hinting, static analysis guidance, multi-agent work frameworks, and oracle generation; we compare LLMs with traditional tools such as EvoSuite, and analyze factors that affect coverage, fault detection, and maintainability. Results: When LLMs are used in conjunction with static analysis or method slicing, competitive and improved coverage can be achieved; achieving target line/branch/path coverage and obtaining robust oracles remain challenging; using multi-stage hints and tools (e.g., interpreters/RAGs) can enhance the correctness of results, and manually verified benchmarks can effectively improve the reliability of evaluations. The tests generated by LLM are promising but not uniformly so: future extensions depend on better oracle reasoning, task-appropriate prompts and scaffolding, and rigorous contamination-aware evaluation with statistical tests and repeatable properties.","","979-8-3315-3677-0","10.1109/IACIS65746.2025.11210946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=11210946","cloud computing;resource demand forecasting;ensemble learning;machine learning","Cloud computing;Machine learning algorithms;Computational modeling;Stacking;Demand forecasting;Static analysis;Benchmark testing;Predictive models;Test pattern generators;Reliability","","","","12","IEEE","5 Nov 2025","22-23 Aug. 2025","22-23 Aug. 2025","IEEE","IEEE Conferences"
