Title,Conference,Year,Resume / Summary
Large Language Models Empowered Personalized Web Agents,WWW '25,2025,"Proposes WebAgents powered by LLMs to handle personalized web tasks, improving interaction and automation capabilities."
LLM4Rerank: LLM-based Auto-Reranking Framework for Recommendations,WWW '25,2025,"Introduces a framework using LLMs to re-rank recommendation lists, leveraging their reasoning capabilities for better accuracy."
DCA-Bench: A Benchmark for Dataset Curation Agents,KDD '25,2025,"A benchmark suite designed to evaluate agents responsible for curating datasets, testing their ability to handle data quality and relevance."
FoodPuzzle: Toward Developing Large Language Model Agents as Autonomous Flavor Scientists,KDD '25,2025,"Explores using LLM agents in food science to autonomously discover and combine flavors, acting as ""flavor scientists""."
HiBench: Benchmarking LLMs Capability on Hierarchical Structure Reasoning,KDD '25,2025,Evaluates the reasoning capabilities of Large Language Models specifically regarding hierarchical structures.
A Framework for Evaluating AI Agents in Open-Ended Conversations via Scripted Simulation,KDD '25,2025,Proposes a simulation-based framework to test and evaluate AI agents in open-ended conversational scenarios.
IdeaBench: Benchmarking Large Language Models for Research Idea Generation,KDD '25,2025,IdeaBench evaluates the creativity and utility of LLMs in generating novel research ideas.
Evaluating GenAI's Effectiveness for Students with Varied Programming Backgrounds in a Software Development Course,SIGCSE TS '25,2025,Investigates how Generative AI tools affect students with different levels of experience in software development courses.
Exploring LLMs Impact on Student-Created User Stories and Acceptance Testing in Software Development,SIGCSE TS '25,2025,Studies how LLMs influence the quality and process of creating user stories and acceptance tests in student projects.
LLM4FP: LLM-Based Program Generation for Triggering Floating-Point Inconsistencies Across Compilers,SC Workshops '25,2025,Uses LLMs to generate test programs specifically designed to find floating-point inconsistencies in different compilers.
Using Code Coverage to Assess Feature Gaps in MPI Correctness Tool Classification Tests,SC Workshops '25,2025,A testing paper focusing on using code coverage metrics to evaluate and improve MPI correctness tools.
Automated MCQA Benchmarking at Scale: Evaluating Reasoning Traces...,SC Workshops '25,2025,"Discusses benchmarking Multiple Choice Question Answering (MCQA) at scale, focusing on reasoning traces for model evaluation."
GridMind: LLMs-Powered Agents for Power System Analysis and Operations,SC Workshops '25,2025,GridMind uses LLM-powered agents to assist in the complex analysis and operation of power systems.
STELLAR: Storage Tuning Engine Leveraging LLM Autonomous Reasoning...,SC '25,2025,STELLAR leverages the reasoning of LLMs to autonomously tune storage systems for high-performance computing.
Testing the Unknown: A Framework for OpenMP Testing via Random Program Generation,SC-W '24,2024,A framework for testing OpenMP implementations by generating random programs to uncover edge cases and bugs.
Stratum: System-Hardware Co-design... for Efficient MoE Serving,MICRO '25,2025,"System-hardware co-design to efficiently serve Mixture-of-Experts (MoE) models, a key architecture in modern LLMs."
Kelle: Co-design KV Caching and eDRAM for Efficient LLM Serving in Edge Computing,MICRO '25,2025,Optimizes LLM serving at the edge by co-designing Key-Value (KV) caching mechanisms with embedded DRAM.
Micro-MAMA: Multi-Agent Reinforcement Learning for Multicore Prefetching,MICRO '25,2025,Applies Multi-Agent Reinforcement Learning (MARL) to optimize data prefetching in multicore processors.
An Empirical Study of the Non-Determinism of ChatGPT in Code Generation,TOSEM '25,2025,"Investigates the non-determinism of ChatGPT in coding tasks, evaluating consistency across benchmarks like HumanEval and SWE-bench."
MapStory: Prototyping Editable Map Animations with LLM Agents,UMAP Adjunct '25,2025,Uses LLM agents to help users prototype and edit map animations through natural language instructions.
agentAR: Creating Augmented Reality Applications with Tool-Augmented LLM-based Autonomous Agents,UMAP Adjunct '25,2025,agentAR employs tool-augmented LLM agents to autonomously assist in creating Augmented Reality (AR) applications.
Premature Trust: How Student Overreliance on GenAI is Seeding Tomorrow's Security Gaps,SIGCITE '25,2025,"Discusses the security implications of students over-relying on GenAI for coding, potentially introducing vulnerabilities."
PentestAgent: Incorporating LLM Agents to Automated Penetration Testing,ASIA CCS '25,2025,"Introduces PentestAgent, an LLM-driven agent designed to automate penetration testing tasks for cybersecurity."
SAFE: A Novel Approach for Software Vulnerability Detection from Enhancing the Capability of Large Language Models,ASIA CCS '25,2025,"SAFE enhances LLMs to improve their ability to detect software vulnerabilities, a key application in security testing."
Generalized Adversarial Code-Suggestions: Exploiting Contexts of LLM-based Code-Completion,ASIA CCS '25,2025,Explores adversarial attacks on LLM-based code completion systems by exploiting context to suggest insecure code.
Automatic Programming: Large Language Models and Beyond,TOSEM '25,2025,"A comprehensive article discussing the role of LLMs in automatic programming, covering code generation, testing, and repair."
Titanus: Enabling KV Cache Pruning and Quantization On-the-Fly for LLM Acceleration,GLSVLSI '25,2025,Hardware acceleration technique for LLMs focusing on pruning and quantizing the KV cache during inference.
ChineseEcomQA: A Scalable E-commerce Concept Evaluation Benchmark for Large Language Models,KDD '25,2025,A benchmark dataset for evaluating LLM understanding of e-commerce concepts in Chinese.
VFLAIR-LLM: A Comprehensive Framework and Benchmark for Split Learning of LLMs,KDD '25,2025,"A framework and benchmark for ""Split Learning"" with LLMs, likely focusing on privacy-preserving distributed training/inference."
Revisiting the Capability of GPT in Solving Coding Problems: A Lesson from Programming with Recursion,SIGCITE '25,2025,"Critically evaluates GPT's ability to solve complex recursive programming problems, highlighting limitations."
Title,Conference / Journal,Year,Resume / Summary
A Survey on Large Language Models for Code Generation,TOSEM,2026,"A comprehensive survey on ""Code LLMs,"" covering evolution, advanced techniques (autonomous agents, RAG), and comparative analysis on benchmarks like HumanEval, MBPP, and SWE-bench."
The Current Challenges of Software Engineering in the Era of Large Language Models,TOSEM,2025,"Identifies 26 key challenges in SE introduced by LLMs, specifically in areas like testing code generation, coverage analysis, and software vulnerability management."
Exploring Automated Assertion Generation via Large Language Models,TOSEM,2025,"Investigates the use of LLMs to automate the generation of assertions for unit testing, aiming to reduce manual effort and improve bug detection (evaluated on Defects4J)."
ContrastRepair: Enhancing Conversation-Based Automated Program Repair via Contrastive Test Case Pairs,TOSEM,2025,"Introduces ContrastRepair, an automated program repair (APR) method that uses contrastive test case pairs to guide LLMs, outperforming previous conversational APR methods."
Requirements Are All You Need: The Final Frontier for End-User Software Engineering,TOSEM,2025,Explores a vision where end-users drive the software lifecycle (including testing and adaptation) using only natural language requirements processed by Generative AI.
Ecosystem of Large Language Models for Code,TOSEM,2025,"Defines and analyzes the ""LLM4Code"" ecosystem, examining how models interact and support tasks like program repair, software testing, and documentation."
LLM-Powered Static Binary Taint Analysis,TOSEM,2025,"Proposes LATTE, the first static binary taint analysis tool powered by LLMs. It automates the extraction of dangerous data flows and is evaluated on standard benchmarks."
Maintainability and Scalability in Machine Learning: Challenges and Solutions,CSUR,2025,"A survey addressing ML engineering challenges, highlighting the lack of adequate unit test suites and code coverage in popular ML libraries."
Research on WebAssembly Runtimes: A Survey,TOSEM,2025,"Surveys WebAssembly runtimes, discussing testing techniques like WasmFuzzer and code coverage analysis for bug detection in runtimes."
Integration of Quantum Accelerators with High Performance Computing...,TQC,2025,"Reviews quantum programming tools, touching on the translation of classical software testing and requirement analysis concepts into the quantum context."
Proceedings of the 24th International Conference on Autonomous Agents and Multiagent Systems,AAMAS '25,2025,"Major conference on agents. Highlights include ""Self-Corrective Mechanisms"" using LLM agents for retrieval and dynamic knowledge graphs."
Companion of the 16th ACM/SPEC International Conference on Performance Engineering,ICPE '25,2025,"Includes workshops on ""Load Testing and Benchmarking of Software Systems"" and ""AI Performance and Optimization in the LLM World""."
Proceedings of the 21st International Conference on Predictive Models and Data Analytics in Software Engineering,PROMISE '25,2025,Focuses on predictive models in SE; highlights mention research on using LLMs for test case prioritization.
Proceedings of the 18th Innovations in Software Engineering Conference,ISEC '25,2025,General SE conference. Highlights discuss the evolution of software testing and optimizing dead code in smart contracts.
Proceedings of the 8th International Conference on Data Science and Management of Data,CODS-COMAD '24,2025,"Data science conference. Highlights include MEQA, a multi-modal enterprise query answering system using a Multi-Agent LLM."
Proceedings of the 2nd Cyber Security in CarS Workshop,CSCS '25,2025,Automotive security workshop. Highlights mention benchmarking LLMs' knowledge of automotive cyberthreats.
Proceedings of the 2025 International Conference on Software Engineering and Computer Applications,SECA '25,2025,"SE conference. Highlights include ""Review Copilot,"" which integrates LLMs into a multi-agent architecture for document triage."
Proceedings of the 2025 6th International Conference on Computer Information and Big Data Applications,CIBDA '25,2025,Big Data conference. Highlights mention T-Mamba as a new benchmark for temporal sequence forecasting.
Proceedings of the 6th European Conference on Software Engineering Education,ECSEE '25,2025,Education focus. Highlights discuss NodeGrade for automatic grading using LLMs and benchmarking in automated short answer grading.
Proceedings of the 2024 2nd International Conference on Information Education and Artificial Intelligence,ICIEAI '24,2025,Education/AI conference. Highlights discuss EduChat (an LLM for education) and benchmarks for engineering education.
\Title,Conference / Journal,Year,Resume / Summary
VulScribeR: Exploring RAG-based Vulnerability Augmentation with LLMs,TOSEM,2025,"Proposes VulScribeR, a method that uses Retrieval-Augmented Generation (RAG) and LLMs to augment vulnerability datasets, addressing the data shortage for deep learning-based detectors."
Do advanced language models eliminate the need for prompt engineering in software engineering?,TOSEM,2025,Investigates whether the reasoning capabilities of advanced LLMs (like o1-mini) negate the need for complex prompt engineering in SE tasks like testing and code generation.
SpecGen: Automated Generation of Formal Program Specifications via Large Language Models,ICSE '25,2025,"Introduces SpecGen, an LLM-based technique to automatically generate formal program specifications, evaluated against benchmarks like SV-COMP."
A Systematic Literature Review on Explainability for ML/DL-based Software Engineering,CSUR,2025,"A comprehensive review of Explainable AI (XAI) in software engineering, noting that ~24% of studies focus on software testing tasks like fault localization and vulnerability detection."
From Triumph to Uncertainty: The Journey of Software Engineering in the AI Era,TOSEM,2025,"Discusses the transformative impact of AI on the software development lifecycle (SDLC), highlighting challenges in ""AI-assisted programming"" and the need for new testing benchmarks (e.g., CoderSecEval)."
UTFix: Change Aware Unit Test Repairing using LLM,PACMPL (OOPSLA),2025,"Presents UTFix, a tool that uses LLMs to repair unit tests broken by code changes. It uses code slicing to maintain high code coverage and fix assertion failures."
On Benchmarking Code LLMs for Android Malware Analysis,ISSTA Companion '25,2025,"Introduces Cama, a benchmarking framework to evaluate the effectiveness of Code LLMs in analyzing Android malware, specifically for function identification and summary."
ClozeMaster: Fuzzing Rust Compiler by Harnessing LLMs for Infilling Masked Real Programs,ICSE '25,2025,"Proposes ClozeMaster, a fuzzing technique for the Rust compiler. It uses LLMs to ""infill"" masked sections of real programs, generating valid and diverse test cases."
CITYWALK: Enhancing LLM-Based C++ Unit Test Generation...,TOSEM,2025,"Presents CITYWALK, a framework that improves LLM-based unit test generation for C++ by incorporating project-dependency awareness and language-specific domain knowledge."
"RepairAgent: An Autonomous, LLM-Based Agent for Program Repair",ICSE '25,2025,"Introduces RepairAgent, an autonomous agent that uses an LLM and a finite state machine to plan and execute actions (invoking tools) to fix software bugs."
SimADFuzz: Simulation-Feedback Fuzz Testing for Autonomous Driving Systems,TOSEM,2025,"Proposes SimADFuzz, a fuzz testing approach for Autonomous Driving Systems (ADS) that utilizes feedback from simulations to generate critical testing scenarios."
API-Guided Dataset Synthesis to Finetune Large Code Models,PACMPL (OOPSLA),2025,"Describes Dgen, a method for synthesizing datasets to fine-tune Large Code Models, focusing on achieving comprehensive API coverage."
Improving Deep Assertion Generation via Fine-Tuning Retrieval-Augmented Pre-Trained Language Models,TOSEM,2025,"Presents RetriGen, a retrieval-augmented generation approach that fine-tunes models to improve the generation of assertions in unit tests."
How Scientists Use Large Language Models to Program,CHI '25,2025,"An empirical study on how scientists use LLMs for programming, highlighting a gap in the adoption of quality control practices like software testing and regression testing."
Software Engineering for OpenHarmony: A Research Roadmap,CSUR,2025,"A roadmap for the OpenHarmony ecosystem, reviewing existing testing approaches (like SapFix and Mobile-Sandbox) and discussing code coverage challenges."
M2CVD: Enhancing Vulnerability Understanding through Multi-Model Collaboration...,TOSEM,2025,"Introduces M2CVD, a system that uses multi-model collaboration (likely agent-based) to enhance the detection and understanding of code vulnerabilities."
Proceedings of the 16th International Conference on Internetware,Internetware '25,2025,"Includes papers like ""CodeCleaner"" (mitigating data contamination in LLM benchmarks), ""LASER"" (autonomous agents for traffic sim), and ""Orion"" (multi-agent RAG)."
Proceedings of the 2025 Workshop on Recent Advances in Resilient... Systems,ARTMAN '25,2025,Workshop proceedings focusing on resilient AI systems. Highlights discussion on machine learning-driven system trustworthiness.
Proceedings of the 2025 Computers and People Research Conference,SIGMIS-CPR '25,2025,"Includes papers discussing why ""Software Testing struggles to attract early-career professionals"" and frameworks for non-professionals."
Proceedings of the 2025 Workshop on Re-design Industrial Control Systems with Security,RICSS '25,2025,"Workshop proceedings. Highlights mention ""Fuzz Testing"" and using code coverage feedback to discover vulnerabilities in industrial protocols (MQTT)."
Proceedings of the 3rd Workshop on eBPF and Kernel Extensions,eBPF '25,2025,Workshop proceedings. Highlights discuss benchmarks for evaluating LLM-based code generators in the context of kernel extensions.
Proceedings of the 2025 International Conference on Generative AI for Business,GAIB '25,2025,"Includes ""Toward Verifiable Misinformation Detection: A Multi-Tool LLM Agent Framework""."
Proceedings of the 54th International Conference on Parallel Processing Workshops,ICPP Workshops '25,2025,Highlights mention benchmarks for evaluating LLMs in coding and using RAG for HPC challenges.

Title,Conference / Journal,Year,Resume / Summary
TerzoN: Human-in-the-Loop Software Testing with a Composite Oracle,PACMSE (FSE),2025,"Proposes TerzoN, a tool that keeps humans in the loop to assist with difficult testing tasks by using a composite oracle to verify test outputs."
Demystifying LLM-Based Software Engineering Agents,PACMSE (FSE),2025,"A study analyzing ""Agentless"" approaches versus complex agentic frameworks. It shows that simple, multi-phase LLM approaches can outperform complex agents on benchmarks like SWE-bench."
CoverUp: Effective High Coverage Test Generation for Python,PACMSE (FSE),2025,"Introduces CoverUp, a tool that generates high-coverage regression tests for Python. It uses code coverage analysis and iterative feedback to guide the LLM."
Kitten: A Simple Yet Effective Baseline for Evaluating LLM-Based Compiler Testing,ISSTA Companion,2025,"Presents Kitten, a mutation-based compiler testing tool. It serves as a strong baseline, often outperforming LLM-based fuzzers (like Fuzz4All) in code coverage and bug detection."
LLM-Enhanced Test Case Prioritization for Complex Software Systems,PCI '24,2025,"Proposes using LLMs to prioritize test cases by analyzing unstructured data (logs, bug reports) in addition to traditional code coverage metrics."
Requirements-Based Test Generation: A Comprehensive Survey,TOSEM,2025,"A survey of requirements-based test generation techniques, highlighting the emerging and underexplored potential of LLMs in this domain."
LLM-Explorer: Towards Efficient and Affordable LLM-based Exploration for Mobile Apps,MOBICOM '25,2025,"Introduces LLM-Explorer, an agent that uses LLMs to generate meaningful UI interactions for mobile app testing, optimizing for coverage and efficiency."
MORepair: Teaching LLMs to Repair Code via Multi-Objective Fine-Tuning,TOSEM,2026,"Presents MORepair, which fine-tunes LLMs using multi-objective optimization. It shows strong performance on HumanEval and SWE-bench subsets."
Refuting LLM-generated Code with Reactive Task Comprehension,ITiCSE,2025,Educational research on using automated test generation to help students identify and refute buggy code generated by LLMs without needing full comprehension.
Top Score on the Wrong Exam: On Benchmarking in Machine Learning for Vulnerability Detection,PACMSE (ISSTA),2025,"Critiques current benchmarks for ML-based vulnerability detection, arguing that function-level binary classification ignores crucial context."
Aligning the Objective of LLM-Based Program Repair,ICSE '25,2025,"Proposes D4C, a framework that aligns LLM generation objectives with program repair goals using artifacts (documents, test failures) to improve patching on Defects4J."
ChatDBG: Augmenting Debugging with Large Language Models,PACMSE (FSE),2025,"Describes ChatDBG, an AI assistant that integrates with standard debuggers to perform root cause analysis and suggest fixes using runtime state information."
UAgent: Adversarial Co-evolution for Targeted Bug Revelation in Unit Testing,ARTMAN '25,2025,A framework where two agents (Test Generator and Mutation Generator) compete in an adversarial game to create better unit tests and expose bugs.
Automated Unit Test Generation via Chain of Thought Prompt and Reinforcement Learning...,TOSEM,2025,"Introduces TestCTRL, which optimizes LLMs for unit test generation using Chain-of-Thought prompting and Reinforcement Learning based on code coverage feedback."
Intent-Driven Network Management with Multi-Agent LLMs: The Confucius Framework,SIGCOMM '25,2025,"Presents Confucius, a multi-agent framework for network management at Meta. It uses agents for intent translation and self-correction in hyper-scale networks."
Evaluating the Generalizability of LLMs in Automated Program Repair,ICSE-NIER '25,2025,Evaluates LLM-based program repair on new datasets (like ConDefects and HumanEval-Java) to test generalizability beyond standard benchmarks.
Assessing the Latent Automated Program Repair Capabilities... using Round-Trip Translation,TOSEM,2025,"Investigates if ""Round-Trip Translation"" (translating code to another language and back) can automatically repair bugs via regression to the mean."
Enhancing Differential Testing With LLMs For Testing Deep Learning Libraries,TOSEM,2025,"Uses LLMs to generate diverse test codes for differential testing of Deep Learning libraries (TensorFlow, PyTorch), identifying new bugs."
On Simulation-Guided LLM-based Code Generation for Safe Autonomous Driving Software,EASE '25,2025,Proposes a method for generating safe code for autonomous driving systems by using simulation feedback to guide the LLM.
Multi-Agent Differential Testing for the Game of Go,FSE Companion,2025,"Introduces MAD4Go, a multi-agent differential testing framework to identify non-optimal moves and errors in Go AI agents."
Title,Conference / Journal,Year,Resume / Summary
Navigating the Landscape of Automated Feedback Generation Techniques for Programming Exercises,TOCE,2025,"A comprehensive review of automated feedback tools, highlighting the use of LLMs and the critical need for public benchmarks to improve reproducibility."
CRISPE: Semantic-Guided Execution Planning and Dynamic Reasoning for Enhancing Code Coverage Prediction,PACMSE (FSE),2025,"Introduces CRISPE, a method that guides LLMs to simulate program execution and better predict code coverage and dynamic behavior, addressing a key weakness in current models."
Advancing Code Coverage: Incorporating Program Analysis with Large Language Models,TOSEM,2025,"Presents TELPA, which combines Search-Based Software Testing (SBST) with LLMs to generate tests specifically for hard-to-cover branches, improving overall code coverage."
Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges,FSE Companion,2025,"Discusses new research challenges in ""Just-in-Time"" testing, focusing on hardening LLM-based systems against errors and catching bugs effectively."
LLMDroid: Enhancing Automated Mobile App GUI Testing Coverage with Large Language Model Guidance,PACMSE (FSE),2025,"Proposes LLMDroid, a tool that uses LLM guidance to break through coverage bottlenecks in automated mobile app GUI testing, significantly outperforming traditional tools."
Hybrid Fuzzing of Infrastructure as Code Programs,ISSTA Companion,2025,"Introduces HIT, a hybrid testing approach for Infrastructure as Code (IaC) that combines fuzzing and concolic execution to improve code coverage."
FuseApplyBench: Multilingual Benchmark for Trustworthy Code Edit Applying Task,ISSTA Companion,2025,"Presents FuseApplyBench, a multilingual benchmark designed to evaluate the trustworthiness and accuracy of LLMs when applying code edits."
Best practice for supply chain in LLM-assisted medical applications,ISSTA Companion,2025,"Documents evaluation practices for LLM-assisted medical apps, including performance metrics, benchmarks, and reliability testing protocols."
Can Generative AI Produce Test Cases? An Experience from the Automotive Domain,FSE Companion,2025,An empirical study in the automotive domain evaluating if GenAI can replace manual test script creation. It finds GenAI useful for drafts but not yet ready to fully replace skilled engineers.
TestFlow: Advancing Mobile UI Testing through Multi-Step Reinforcement Learning,ISSTA Companion,2025,"Proposes TestFlow, a mobile UI testing tool using multi-step reinforcement learning to improve upon greedy agent-based approaches."
Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models,MM '25,2025,Introduces a model-intrinsic safety augmentation method for Vision-Language Models that uses internal semantic understanding for self-correction.
AEGIS: An Agent-based Framework for Bug Reproduction from Issue Descriptions,FSE Companion,2025,"Presents AEGIS, a multi-agent framework powered by LLMs that automatically reproduces bugs by analyzing issue descriptions."
Doc2OracLL: Investigating the Impact of Documentation on LLM-Based Test Oracle Generation,PACMSE (FSE),2025,Investigates how the quality and presence of code documentation impact the effectiveness of LLM-based test oracle generation.
Leveraging LLM Enhanced Commit Messages to Improve Machine Learning Based Test Case Prioritization,PROMISE '25,2025,Demonstrates that enriching commit messages with LLMs significantly improves the performance of Machine Learning-based test case prioritization models.
On the Brittleness of Legacy Web UI Testing: A Pragmatic Perspective,ISSTA Companion,2025,Discusses the brittleness of web UI testing and introduces a pragmatic benchmark based on long-term monitoring of real-world web applications.
A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs,ICSE '25,2025,"Introduces AutoRestTest, which uses a multi-agent reinforcement learning approach combined with LLMs to generate inputs and test REST APIs more effectively."
From Large Language Models to Adversarial Malware: How far are we,ISSTA Companion,2025,"A study investigating the capability of LLMs to generate adversarial malware that can evade detection systems, highlighting security risks."
Patch the Leak: Strengthening CodeLLMs Against Privacy Extraction Threats,ISSTA Companion,2025,"Examines privacy risks in Code LLMs, showing that current anonymization methods are insufficient against privacy extraction attacks."
UCC '25: Proceedings of the 18th IEEE/ACM International Conference on Utility and Cloud Computing,UCC '25,2025,"Conference proceedings. Highlights include papers on ""Agentic Edge Intelligence"" and ""Agentic Federated LLMs"" for guardrail inspection."
"icABCD '25: Proceedings... Artificial Intelligence, Big Data, Computing...",icABCD '25,2025,"Conference proceedings. Highlights include ""Human-Inspired Communication in Multi-Agent Environments"" and ""Network Architecture for Value Enhanced LLM Use""."